{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AnoushkaVijay/Leukemia_GAN/blob/main/Featurization_Training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0l_aS9-gs2DC"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the training and validation paths of the respective CSVs\n",
        "TRAINING_PATH = \"\"\n",
        "VALIDATION_PATH = \"\""
      ],
      "metadata": {
        "id": "OBMRIfKJa523"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "# Read the datasets\n",
        "training_data = pd.read_csv(TRAINING_PATH)\n",
        "validation_data = pd.read_csv(VALIDATION_PATH)"
      ],
      "metadata": {
        "id": "VJ8TQBpotFq3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#view the data\n",
        "training_data.head()"
      ],
      "metadata": {
        "id": "Ik5sKwrwbzZv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#view the data\n",
        "validation_data.head()"
      ],
      "metadata": {
        "id": "RhGD9cR8b6g_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#label encoding for training data\n",
        "labels = training_data['label'].unique()\n",
        "labels.sort()\n",
        "print(labels)\n",
        "\n",
        "valid_labels = validation_data['label'].unique()\n",
        "valid_labels.sort()\n",
        "print(valid_labels)"
      ],
      "metadata": {
        "id": "3AgWZOJftNxi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# training data label distribution\n",
        "plt.figure(figsize = (15,5))\n",
        "sns.countplot(data = training_data, x = \"label\")\n",
        "plt.title(\"Label Distribution for Training Data\")\n",
        "plt.xlabel(\"Category\")\n",
        "plt.ylabel(\"Label count\")\n",
        "plt.show();"
      ],
      "metadata": {
        "id": "vB2gw42L29d-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# validation data label distribution\n",
        "plt.figure(figsize = (15,5))\n",
        "sns.countplot(data = validation_data, x = \"label\")\n",
        "plt.title(\"Label Distribution for Validation Data\")\n",
        "plt.xlabel(\"Category\")\n",
        "plt.ylabel(\"Label count\")\n",
        "plt.show();"
      ],
      "metadata": {
        "id": "ges4KKBP3iU9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#label encoding the training data\n",
        "training_data['label'] = pd.factorize(training_data['label'], sort = True)[0]\n",
        "training_data.head()"
      ],
      "metadata": {
        "id": "X-qAhJIatacT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "validation_data['label'] = pd.factorize(validation_data['label'], sort = True)[0]\n",
        "validation_data.head()"
      ],
      "metadata": {
        "id": "YFVT1yEq0Jzr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "x_train = training_data.iloc[:, :-1].values\n",
        "x_valid = validation_data.iloc[:, :-1].values\n",
        "y_train = training_data.iloc[:, -1].values\n",
        "y_valid = validation_data.iloc[:, -1].values\n",
        "\n",
        "print(x_train.shape)\n",
        "print(x_valid.shape)\n",
        "print(y_train.shape)\n",
        "print(y_valid.shape)"
      ],
      "metadata": {
        "id": "9bYM9Aastn2C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "def model_evaluations(y_true, y_pred):\n",
        "  import matplotlib.pyplot as plt\n",
        "  import seaborn as sns\n",
        "\n",
        "  acc_score = accuracy_score(y_true, y_pred)\n",
        "  print(\"Accuracy score: {}\\n\".format(acc_score))\n",
        "\n",
        "  print(\"Classification Report: {}\".format(classification_report(y_true, y_pred)))\n",
        "\n",
        "  plt.figure(figsize = (10,10))\n",
        "  sns.heatmap(confusion_matrix(y_true, y_pred),  annot = True, fmt=\"g\", cmap = \"Blues\", xticklabels = labels, yticklabels = labels)\n",
        "  plt.title(\"Consfuion Matrix\")\n",
        "  plt.show()\n",
        "'''"
      ],
      "metadata": {
        "id": "WcoWtRlywGvc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cofusion Matrix in Percentage & Classification Report"
      ],
      "metadata": {
        "id": "IQdomsU7LaaN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "import numpy as np\n",
        "\n",
        "def model_evaluations(y_true, y_pred):\n",
        "  import matplotlib.pyplot as plt\n",
        "  import seaborn as sns\n",
        "\n",
        "  acc_score = accuracy_score(y_true, y_pred)\n",
        "  print(\"Accuracy score: {}\\n\".format(acc_score))\n",
        "\n",
        "  print(\"Classification Report: {}\".format(classification_report(y_true, y_pred)))\n",
        "\n",
        "   # Compute normalized confusion matrix\n",
        "  cm = confusion_matrix(y_true, y_pred, normalize='true')\n",
        "\n",
        "    # to get percentages\n",
        "  cm_percentage = cm * 100\n",
        "\n",
        "    # Create annotations for confusion matrix values with the percentage sign\n",
        "  annotations = np.array([[f'{val:.2f}%' for val in row] for row in cm_percentage])\n",
        "\n",
        "\n",
        "  plt.figure(figsize = (10,10))\n",
        "  sns.heatmap(cm,  annot = annotations, fmt=\"\", cmap = \"Blues\", xticklabels = labels, yticklabels = labels)\n",
        "  plt.title(\"Consfusion Matrix\")\n",
        "  plt.show()\n"
      ],
      "metadata": {
        "id": "XXXdWT2iLQUG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### KNN"
      ],
      "metadata": {
        "id": "R1UUaWZLuiy-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "\n",
        "K = [i for i in range(2,15)]\n",
        "accuracies = []\n",
        "\n",
        "for k_value in K:\n",
        "  main_model = KNeighborsClassifier(n_neighbors=k_value, n_jobs = -1)\n",
        "  main_model.fit(x_train,y_train)\n",
        "  y_pred = main_model.predict(x_valid)\n",
        "  accuracies.append(accuracy_score(y_valid, y_pred))\n",
        "  print(\"Neighbour {} experiment done\".format(k_value))"
      ],
      "metadata": {
        "id": "Rz1AvV_LuiFP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "plt.figure(figsize = (5,5))\n",
        "plt.plot(K, accuracies, color = \"red\")\n",
        "plt.xlabel(\"Number of Neighbours\")\n",
        "plt.ylabel(\"Accuracy Value\")\n",
        "plt.title(\"Accuracy vs Number of Neighbours\")\n",
        "plt.xticks([i for i in range(16)])\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "rncJ7AAtyAfT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#best model\n",
        "best_model_one = KNeighborsClassifier(n_neighbors=5, n_jobs = -1)\n",
        "best_model_one.fit(x_train, y_train)\n",
        "best_ypred = best_model_one.predict(x_valid)\n",
        "model_evaluations(y_valid, best_ypred)"
      ],
      "metadata": {
        "id": "cv1cqjtnvW7K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### RandomForest"
      ],
      "metadata": {
        "id": "e17m9uUa15Y_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "max_depth = [1,2,3,4,5,6,7]\n",
        "n_trees = [i for i in range(10,110,10)]\n",
        "\n",
        "all_acc = []\n",
        "\n",
        "for depth in max_depth:\n",
        "  acc = []\n",
        "  for tree in n_trees:\n",
        "    model1 = RandomForestClassifier(n_estimators=tree, max_depth=depth, n_jobs = -1)\n",
        "    model1.fit(x_train,y_train)\n",
        "    y_pred = model1.predict(x_valid)\n",
        "    accuracy = accuracy_score(y_valid, y_pred)\n",
        "    acc.append(accuracy)\n",
        "    print(\"Depth: {} and Tree: {} done\".format(depth, tree))\n",
        "  all_acc.append(acc)"
      ],
      "metadata": {
        "id": "wmH6s8HO14sJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.figure(figsize = (15,8))\n",
        "for index in range(len(max_depth)):\n",
        "  plt.plot(n_trees,all_acc[index],\"*-\", label = f\"max_depth: {index + 1}\")\n",
        "plt.xlabel(\"Number of trees\")\n",
        "plt.ylabel(\"Accuracy Value\")\n",
        "plt.legend(loc = \"best\")\n",
        "plt.xticks([i for i in range(10,110,10)])\n",
        "plt.grid(True)\n",
        "plt.title(\"Accuracy values respective to max_depth and number of trees\")"
      ],
      "metadata": {
        "id": "CMyaqkoa6YkM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# run the best model\n",
        "best_model_two = RandomForestClassifier()\n",
        "best_model_two.fit(x_train, y_train)\n",
        "best_ypred = best_model_two.predict(x_valid)\n",
        "model_evaluations(y_valid, best_ypred)"
      ],
      "metadata": {
        "id": "Pyy6JPY20f9c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### MLP"
      ],
      "metadata": {
        "id": "jW7Wbt_ALiEV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "learning_rate = [0.01, 0.05, 0.001, 0.0001, 0.00001]\n",
        "epochs = [i for i in range(10,110,10)]\n",
        "\n",
        "all_acc_mlp = []\n",
        "\n",
        "for lr in learning_rate:\n",
        "  acc_mlp = []\n",
        "  for epo in epochs:\n",
        "    model1 = MLPClassifier(learning_rate_init=lr, max_iter=epo)\n",
        "    model1.fit(x_train,y_train)\n",
        "    y_pred = model1.predict(x_valid)\n",
        "    accuracy = accuracy_score(y_valid, y_pred)\n",
        "    acc_mlp.append(accuracy)\n",
        "    print(\"Depth: {} and Learning Rate: {} done\".format(lr, epo))\n",
        "  all_acc_mlp.append(acc_mlp)"
      ],
      "metadata": {
        "id": "L9hRF0uGLjvd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.figure(figsize = (15,8))\n",
        "for index in range(len(learning_rate)):\n",
        "  plt.plot(epochs,all_acc_mlp[index],\"*-\", label = f\"learning_rate: {learning_rate[index]}\")\n",
        "plt.xlabel(\"Number of epochs\")\n",
        "plt.ylabel(\"Accuracy Value\")\n",
        "plt.legend(loc = \"best\")\n",
        "plt.xticks([i for i in range(10,110,10)])\n",
        "plt.grid(True)\n",
        "plt.title(\"Accuracy values respective to Learning rate and number of epochs\")"
      ],
      "metadata": {
        "id": "UTMsRCJnMiWc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#please train the data with best selected model\n",
        "best_model_three = MLPClassifier(learning_rate_init=0.001 , max_iter=60)\n",
        "best_model_three.fit(x_train, y_train)\n",
        "best_ypred = best_model_three.predict(x_valid)\n",
        "model_evaluations(y_valid, best_ypred)"
      ],
      "metadata": {
        "id": "93tArnfS5bsd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Run the best algorithm with best hyper parameters\n",
        "- Compulsory"
      ],
      "metadata": {
        "id": "LNMhZu2uRCFg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#please train the data with best selected model\n",
        "final_best = MLPClassifier(learning_rate_init=0.001 , max_iter=60)\n",
        "final_best.fit(x_train, y_train)\n",
        "best_ypred = final_best.predict(x_valid)\n",
        "model_evaluations(y_valid, best_ypred)"
      ],
      "metadata": {
        "id": "s4r7qDNhQkF6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Save the best model"
      ],
      "metadata": {
        "id": "1zNJQczY83e5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "fh = open(\"\", \"wb\")\n",
        "pickle.dump(final_best, fh)\n",
        "fh.close()"
      ],
      "metadata": {
        "id": "d6HeYo7E85Dp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}