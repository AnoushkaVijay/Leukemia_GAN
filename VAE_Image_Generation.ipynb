{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AnoushkaVijay/Leukemia_GAN/blob/main/VAE_Image_Generation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6NyT-p7U42vG"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mksqc8GggQvX"
      },
      "outputs": [],
      "source": [
        "PATH = \"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZvMQiyjLgnoA"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.utils import image_dataset_from_directory\n",
        "image_dataset = image_dataset_from_directory(directory = PATH, batch_size = 32,color_mode='rgb', image_size = (64,64), shuffle=True)\n",
        "# Normalize the pixel values to be between 0 and 1\n",
        "image_dataset = image_dataset.map(lambda x, y: (x / 255.0, y))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F7z5ekiJi6xm"
      },
      "outputs": [],
      "source": [
        "# for the imports\n",
        "import numpy as np\n",
        "import random\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from keras.models import Model\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.layers import LeakyReLU, Dense, Dropout, Input, BatchNormalization\n",
        "from tensorflow.keras.optimizers import Adam, RMSprop\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm_notebook\n",
        "import os\n",
        "import sys"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "50_6mrNlh3Xr"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "for image_batch, label_batch in image_dataset:\n",
        "    plt.imshow(image_batch[0])\n",
        "    print(np.max(image_batch[0]))\n",
        "    plt.show()\n",
        "    print(label_batch[0])\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oX_GKcy5g1j9"
      },
      "outputs": [],
      "source": [
        "# Set the dimensions of the noise\n",
        "latent_dim = 128\n",
        "#Using this class to get the sampling using the gaussian distribution and standard mean to basically create the noise\n",
        "class Sampling(layers.Layer):\n",
        "    \"\"\"Uses (z_mean, z_log_var) to sample z, the vector encoding a digit.\"\"\"\n",
        "\n",
        "    def call(self, inputs):\n",
        "        z_mean, z_log_var = inputs\n",
        "        batch = tf.shape(z_mean)[0]\n",
        "        dim = tf.shape(z_mean)[1]\n",
        "        epsilon = tf.keras.backend.random_normal(shape=(batch, dim))\n",
        "        return z_mean + tf.exp(0.5 * z_log_var) * epsilon"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z2XjFCRdik_a"
      },
      "outputs": [],
      "source": [
        "#VAE ENCODER\n",
        "encoder_inputs = keras.Input(shape=(64, 64, 3))\n",
        "x = layers.Conv2D(16, 5, activation=\"relu\", strides=2, padding=\"same\")(encoder_inputs)\n",
        "x = layers.Conv2D(32, 5, activation=\"relu\", strides=2, padding=\"same\")(x)\n",
        "x = layers.Conv2D(64, 5, activation=\"relu\", strides=2, padding=\"same\")(x)\n",
        "x = layers.Conv2D(128, 5, activation=\"relu\", strides=2, padding=\"same\")(x)\n",
        "\n",
        "x = layers.Flatten()(x)\n",
        "\n",
        "z_mean = layers.Dense(latent_dim, name=\"z_mean\")(x)\n",
        "z_log_var = layers.Dense(latent_dim, name=\"z_log_var\")(x)\n",
        "z = Sampling()([z_mean, z_log_var])\n",
        "encoder = keras.Model(encoder_inputs, [z_mean, z_log_var, z], name=\"encoder\")\n",
        "encoder.summary()\n",
        "#each layer has that many feature maps layered on top of each other - the third line is 32 32X32 feature maps layered on top of each other\n",
        "#at the end it flattens it out meaning that the final product is just a one dimensional array of values - take mean and variation then add it to size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PKEV4kntkNQl"
      },
      "outputs": [],
      "source": [
        "#Code for Decoder\n",
        "#VAE Decoder\n",
        "latent_inputs = keras.Input(shape=(latent_dim,))\n",
        "x = layers.Dense(8 * 8 * 64, activation=\"relu\")(latent_inputs)\n",
        "x = layers.Reshape((8, 8, 64))(x)\n",
        "x = layers.Conv2DTranspose(128, 3, activation=\"relu\", strides=2, padding=\"same\")(x)\n",
        "x = layers.Conv2DTranspose(64, 5, activation=\"relu\", strides=2, padding=\"same\")(x)\n",
        "x = layers.Conv2DTranspose(64, 5, activation=\"relu\", strides=2, padding=\"same\")(x)\n",
        "decoder_outputs = layers.Conv2DTranspose(3, 5, activation=\"sigmoid\", padding=\"same\")(x)\n",
        "\n",
        "decoder = keras.Model(latent_inputs, decoder_outputs, name=\"decoder\")\n",
        "decoder.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w2tU15QKknKy"
      },
      "outputs": [],
      "source": [
        "class VAE(keras.Model):\n",
        "    def __init__(self, encoder, decoder, **kwargs):\n",
        "        super(VAE, self).__init__(**kwargs)\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "\n",
        "    def train_step(self, data):\n",
        "        if isinstance(data, tuple):\n",
        "            data = data[0]\n",
        "        with tf.GradientTape() as tape:\n",
        "            z_mean, z_log_var, z = encoder(data)\n",
        "            reconstruction = decoder(z)\n",
        "            reconstruction_loss = tf.reduce_mean(\n",
        "                keras.losses.binary_crossentropy(data, reconstruction)\n",
        "            )\n",
        "            reconstruction_loss *= 64*64\n",
        "            kl_loss = 1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var)\n",
        "            kl_loss = tf.reduce_mean(kl_loss)\n",
        "            kl_loss *= -0.5\n",
        "            total_loss = reconstruction_loss + kl_loss\n",
        "        grads = tape.gradient(total_loss, self.trainable_weights)\n",
        "        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
        "        return {\n",
        "            \"loss\": total_loss,\n",
        "            \"reconstruction_loss\": reconstruction_loss,\n",
        "            \"kl_loss\": kl_loss,\n",
        "        }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oJFCW8gTkpYX"
      },
      "outputs": [],
      "source": [
        "vae_optimizer = keras.optimizers.Adam()\n",
        "# learning_rate=0.00001\n",
        "epochs = 500\n",
        "batch_size = 15\n",
        "\n",
        "\n",
        "# Create the vae model\n",
        "vae = VAE(encoder, decoder)\n",
        "vae.compile(optimizer=vae_optimizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cUY1CBZ_krXv"
      },
      "outputs": [],
      "source": [
        "BASE_DIR = ''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f6RWk2sSkvNr"
      },
      "outputs": [],
      "source": [
        "vae_checkpoint_dir = os.path.join(BASE_DIR, 'VAE_checkpoints')\n",
        "vae_checkpoint_prefix = os.path.join(vae_checkpoint_dir, \"checkpoints\")\n",
        "\n",
        "vae_checkpoint = tf.train.Checkpoint(vae_optimizer=vae_optimizer,\n",
        "                                 vae=vae,)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qNw1DwG5ky6O"
      },
      "outputs": [],
      "source": [
        "usePreTrainVae = False\n",
        "\n",
        "if usePreTrainVae:\n",
        "    vae_checkpoint.restore(tf.train.latest_checkpoint(vae_checkpoint_dir))\n",
        "else:\n",
        "    vae.fit(image_dataset, epochs=500, batch_size=15)\n",
        "    vae_checkpoint.save(file_prefix = vae_checkpoint_prefix)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ccAif7NBk6qI"
      },
      "outputs": [],
      "source": [
        "#test VAE - has it been trained correctly or not?\n",
        "import numpy as np\n",
        "for image_batch, label_batch in image_dataset:\n",
        "    first_image = np.array(image_batch[0])\n",
        "    first_image = first_image.reshape(1,64,64,3)\n",
        "\n",
        "    noise = np.random.normal(0, 1, size=(1, latent_dim))\n",
        "    z_p = encoder.predict(([first_image]))[2]\n",
        "\n",
        "    x_p = decoder.predict(z_p)\n",
        "\n",
        "    plt.imshow(first_image[0])\n",
        "    plt.show()\n",
        "    plt.axis('off')\n",
        "    plt.imshow(x_p[0])\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qUeRWAmEqZTI"
      },
      "outputs": [],
      "source": [
        "#adam = Adam(learning_rate=0.0002, beta_1=0.5)\n",
        "g_optim = tf.keras.optimizers.Adam(0.0002, beta_1=0.5)\n",
        "d_optim = tf.keras.optimizers.Adam(0.0002, beta_1=0.5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4HWJsmDqjA3t"
      },
      "outputs": [],
      "source": [
        "# adding in the image generator\n",
        "generator_inputs = keras.Input(shape=(latent_dim,))\n",
        "\n",
        "x = layers.Dense(1024, activation=\"relu\")(generator_inputs)\n",
        "x = BatchNormalization()(x)\n",
        "x = layers.Dense(2048, activation=\"relu\")(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = layers.Reshape((4, 4, 128))(x)\n",
        "x = layers.Conv2DTranspose(128, 5, activation=\"relu\", strides=2, padding=\"same\")(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = layers.Conv2DTranspose(64, 5, activation=\"relu\", strides=2, padding=\"same\")(x)\n",
        "x = BatchNormalization()(x)\n",
        "x= layers.Conv2DTranspose(32, 5, activation=\"relu\", strides=2, padding=\"same\")(x)\n",
        "generator_outputs = layers.Conv2DTranspose(3, 5, activation=\"sigmoid\", strides=2, padding=\"same\")(x)\n",
        "\n",
        "\n",
        "generator = keras.Model(generator_inputs, generator_outputs, name=\"generator\")\n",
        "generator.compile(loss='binary_crossentropy', optimizer=g_optim, metrics=['accuracy'])\n",
        "generator.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eNjZ25aUkIoJ"
      },
      "outputs": [],
      "source": [
        "# Discriminator - is it real or not?\n",
        "discriminator_inputs = keras.Input(shape=(64, 64, 3))\n",
        "x = layers.Conv2D(16, 5, strides=2, padding=\"same\")(discriminator_inputs)\n",
        "x = LeakyReLU(alpha=0.3)(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Dropout(0.2)(x)\n",
        "x = layers.Conv2D(32, 5, strides=2, padding=\"same\")(x)\n",
        "x = LeakyReLU(alpha=0.3)(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Dropout(0.2)(x)\n",
        "x = layers.Conv2D(32, 5, strides=1, padding=\"same\")(x)\n",
        "x = LeakyReLU(alpha=0.3)(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Dropout(0.2)(x)\n",
        "x = layers.Conv2D(64, 5, strides=2, padding=\"same\")(x)\n",
        "x = LeakyReLU(alpha=0.3)(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Dropout(0.2)(x)\n",
        "x = layers.Conv2D(64, 5, strides=1, padding=\"same\")(x)\n",
        "x = LeakyReLU(alpha=0.3)(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = layers.Conv2D(128, 5, strides=2, padding=\"same\")(x)\n",
        "x = LeakyReLU(alpha=0.3)(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = layers.Flatten()(x)\n",
        "x = layers.Dense(1024)(x)\n",
        "discriminator_outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "\n",
        "\n",
        "\n",
        "discriminator = keras.Model(discriminator_inputs, discriminator_outputs, name=\"discriminator\")\n",
        "discriminator.compile(loss='binary_crossentropy', optimizer=d_optim, metrics=['accuracy'])\n",
        "discriminator.trainable = False\n",
        "\n",
        "discriminator.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8e6OX4HzljLJ"
      },
      "outputs": [],
      "source": [
        "# Combines both models so I can use training to work on the model\n",
        "inputs = keras.Input(shape=(latent_dim, ))\n",
        "hidden = generator(inputs)\n",
        "output = discriminator(hidden)\n",
        "gan = Model(inputs, output)\n",
        "gan_optim = tf.keras.optimizers.Adam(0.002, beta_1=0.5)\n",
        "gan.compile(loss='binary_crossentropy', optimizer=gan_optim, metrics=['accuracy'])\n",
        "gan.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PenxVIp1l978"
      },
      "outputs": [],
      "source": [
        "# Helper functions to plot losses/generated images and observe if the loss is reducing with the number of epochs\n",
        "def plot_loss(losses):\n",
        "    \"\"\"\n",
        "    @losses.keys():\n",
        "        0: loss\n",
        "        1: accuracy\n",
        "    \"\"\"\n",
        "    d_loss = [v[0] for v in losses[\"D\"]]\n",
        "    g_loss = [v[0] for v in losses[\"G\"]]\n",
        "    print(d_loss)\n",
        "    print(g_loss)\n",
        "    plt.figure(figsize=(10,8))\n",
        "    plt.plot(d_loss, label=\"Discriminator loss\")\n",
        "    plt.plot(g_loss, label=\"Generator loss\")\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "def plot_generated(n_ex=10, dim=(1, 10), figsize=(12, 2)):\n",
        "    noise = np.random.normal(0, 1, size=(n_ex, latent_dim))\n",
        "    x_p = decoder.predict(noise)\n",
        "    z_p = encoder.predict(x_p)[2]\n",
        "    generated_images = generator.predict(z_p)\n",
        "    generated_images = generated_images.reshape(n_ex, 64, 64,3)\n",
        "\n",
        "    plt.figure(figsize=figsize)\n",
        "    for i in range(generated_images.shape[0]):\n",
        "        plt.subplot(dim[0], dim[1], i+1)\n",
        "        plt.imshow(generated_images[i], interpolation='nearest')\n",
        "        plt.axis('off')\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NGkXrcNRkS4C"
      },
      "outputs": [],
      "source": [
        "# Saving the model\n",
        "def save_model(epochs):\n",
        "    generator.save(\"\".format(epochs))\n",
        "    discriminator.save(\"\".format(epochs))\n",
        "    generator.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pVsR3rHEnDRP"
      },
      "outputs": [],
      "source": [
        "# Set up a vector (dict) to store the losses\n",
        "losses = {\"D\":[], \"G\":[]}\n",
        "\n",
        "def train(epochs=500, plt_frq=1, BATCH_SIZE=128):\n",
        "    set_tf_loglevel(logging.FATAL)\n",
        "    batchCount = len(image_dataset)\n",
        "    print('Epochs:', epochs)\n",
        "    print('Batch size:', BATCH_SIZE)\n",
        "    print('Batches per epoch:', batchCount)\n",
        "\n",
        "    for e in tqdm_notebook(range(1, epochs+1)):\n",
        "        if e == 1 or e%plt_frq == 0:\n",
        "            print('-'*15, 'Epoch %d' % e, '-'*15)\n",
        "        print(len(image_dataset))\n",
        "        count = 0\n",
        "        for image_batch,batch_label in image_dataset:  # tqdm_notebook(range(batchCount), leave=False):\n",
        "            count = count + 1\n",
        "            # Create a batch by drawing random index numbers from the training set\n",
        "            print(\"test\" + str(count))\n",
        "\n",
        "            # image_batch = image_batch.reshape(128, 784) #why TODO\n",
        "            # Create noise vectors for the generator\n",
        "            noise = np.random.normal(0, 1, size=(BATCH_SIZE, latent_dim))\n",
        "\n",
        "            #z => vae decoder\n",
        "            x_p = decoder.predict(noise)\n",
        "            z_p = encoder.predict(x_p)[2]\n",
        "\n",
        "\n",
        "            # Generate the images from the noise\n",
        "            generated_images = generator.predict(z_p)\n",
        "            X = np.concatenate((image_batch, generated_images))\n",
        "\n",
        "            # Create labels\n",
        "            y = np.zeros(len(image_batch) + BATCH_SIZE)\n",
        "            y[:len(image_batch)] = 0.9  # One-sided label smoothing\n",
        "\n",
        "            # Train discriminator on generated images\n",
        "            discriminator.trainable = True\n",
        "            d_loss = discriminator.train_on_batch(X, y)\n",
        "\n",
        "            # Train generator\n",
        "            # noise = np.random.normal(0, 1, size=(BATCH_SIZE, latent_dim))\n",
        "            #z => vae decoder\n",
        "            # x_p = decoder.predict(noise)\n",
        "            # z_p = encoder.predict(x_p)[2]\n",
        "\n",
        "\n",
        "            #y2 = np.ones(BATCH_SIZE)\n",
        "            y2 = np.ones(BATCH_SIZE)\n",
        "            discriminator.trainable = False\n",
        "            g_loss = gan.train_on_batch(z_p, y2)\n",
        "            #losses[\"D\"].append(d_loss)\n",
        "            #losses[\"G\"].append(g_loss)\n",
        "            #if count ==23:\n",
        "            #  losses[\"D\"].append(d_loss)\n",
        "            #  losses[\"G\"].append(g_loss)\n",
        "        # Only store losses from final batch of epoch\n",
        "        losses[\"D\"].append(d_loss)\n",
        "        losses[\"G\"].append(g_loss)\n",
        "        print('epochs', e)\n",
        "        if e%500 ==0:\n",
        "            save_model(e)\n",
        "        # Update the plots\n",
        "        if e == 1 or e%plt_frq == 0:\n",
        "            plot_generated()\n",
        "    plot_loss(losses)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mQ1_5k6Poei9"
      },
      "outputs": [],
      "source": [
        "import logging\n",
        "import os\n",
        "\n",
        "def set_tf_loglevel(level):\n",
        "    if level >= logging.FATAL:\n",
        "        os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
        "    if level >= logging.ERROR:\n",
        "        os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
        "    if level >= logging.WARNING:\n",
        "        os.environ['TF_CPP_MIN_LOG_LEVEL'] = '1'\n",
        "    else:\n",
        "        os.environ['TF_CPP_MIN_LOG_LEVEL'] = '0'\n",
        "    logging.getLogger('tensorflow').setLevel(level)\n",
        "set_tf_loglevel(logging.FATAL)\n",
        "train(epochs=2000, plt_frq=20, BATCH_SIZE=20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qYfWWN95K84R"
      },
      "outputs": [],
      "source": [
        "num_images = 2232\n",
        "\n",
        "\n",
        "noise =np.random.normal(0, 1, size=(num_images, latent_dim))\n",
        "x_p = decoder.predict(noise)\n",
        "z_p = encoder.predict(x_p)[2]\n",
        "generated_images = generator.predict(z_p)\n",
        "generated_images = generated_images.reshape(num_images, 64, 64,3)\n",
        "\n",
        "#plt.figure(figsize=(10,10))\n",
        "#for i in range(generated_images.shape[0]):\n",
        "#    plt.subplot(3, 4, i+1)\n",
        "#    plt.imshow(generated_images[i], interpolation='nearest', cmap='gray_r')\n",
        "#    plt.axis('off')\n",
        "\n",
        "#plt.show()\n",
        "\n",
        "\n",
        "## CHANGE THE CLASS NAME TO THE TRAINED GAN CLASS\n",
        "from matplotlib import pyplot as plt\n",
        "for i in range(num_images):\n",
        "\n",
        "    plt.imsave(\"<Drive Path>\" + f\"gan_generated_normal_category_{i}.png\", generated_images[i])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-FSAonTwm5iN"
      },
      "outputs": [],
      "source": [
        "# Loads generator and discriminator to get the already trained version\n",
        "generator = tf.keras.models.load_model(\"\")\n",
        "discriminator = tf.keras.models.load_model(\"\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}