{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AnoushkaVijay/Leukemia_GAN/blob/main/Featurization_Train_Validation_Test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1e220a42",
      "metadata": {
        "id": "1e220a42"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5e07ef7c",
      "metadata": {
        "id": "5e07ef7c"
      },
      "outputs": [],
      "source": [
        "# Please replace the brackets below with the drive location of your folder which included subfolders for images\n",
        "# Sample path: /content/drive/My Drive/ImageClassification\n",
        "PATH = ''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b652e29b",
      "metadata": {
        "id": "b652e29b"
      },
      "outputs": [],
      "source": [
        "def get_optimizer(optimizer_name, learning_rate):\n",
        "    # Import keras optimizers\n",
        "    from tensorflow.keras.optimizers import Adam, Adadelta, Adagrad, Adamax, Ftrl, Nadam, RMSprop, SGD\n",
        "    print('Selected Optimizer', optimizer_name)\n",
        "    switcher = {\n",
        "        'Adadelta': Adadelta(lr=learning_rate),\n",
        "        'Adagrad': Adagrad(lr=learning_rate),\n",
        "        'Adam': Adam(lr=learning_rate),\n",
        "        'Adamax': Adamax(lr=learning_rate),\n",
        "        'FTRL': Ftrl(lr=learning_rate),\n",
        "        'NAdam': Nadam(lr=learning_rate),\n",
        "        'RMSprop': RMSprop(lr=learning_rate),\n",
        "        'Gradient Descent': SGD(lr=learning_rate)\n",
        "    }\n",
        "    # If optimizer_name is empty, Adam will be return as default optimizer\n",
        "    return switcher.get(optimizer_name, Adam(lr=learning_rate))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_tf_dataset(PATH, model):\n",
        "    # This function passes all images provided in PATH\n",
        "    # and passes them through the model.\n",
        "    # The result is a featurized image along with labels\n",
        "    data = []\n",
        "    IMG_SIZE = (224, 224)\n",
        "    file_list = []\n",
        "\n",
        "    # Get the list of subfolders\n",
        "    sub_dirs = next(os.walk(PATH))[1]\n",
        "    print(sub_dirs)\n",
        "    num_images = 0\n",
        "\n",
        "    # Create a list of lists\n",
        "    # Number of lists is same as the number of subfolders\n",
        "    # Number of items in the sub-list is the number of\n",
        "    # images in each sub-folder\n",
        "    for category in sub_dirs:\n",
        "        files = next(os.walk(PATH + '/' + category), (None, None, []))[2]\n",
        "        filenames = [PATH + '/' + category + '/' + file for file in files]\n",
        "        num_images += len(filenames)\n",
        "        file_list.append(filenames)\n",
        "\n",
        "    labels = []\n",
        "    # Every image is pre-processed and passed thought the model\n",
        "    # Label is created for every image\n",
        "    for category in file_list:\n",
        "        for img_path in category:\n",
        "            img = tf.keras.preprocessing.image.load_img(img_path, target_size=IMG_SIZE)\n",
        "            img_array = tf.keras.preprocessing.image.img_to_array(img)\n",
        "            img_batch = np.expand_dims(img_array, axis=0)\n",
        "            img_preprocessed = preprocess_input(img_batch)\n",
        "            data.append(model.predict(img_preprocessed))\n",
        "            labels.append(img_path.split('/')[-2])\n",
        "\n",
        "\n",
        "    # Make sure dimensions are (num_samples, 1280)\n",
        "    data = np.squeeze(np.array(data))\n",
        "    labels = np.reshape(labels, (-1,1))\n",
        "    return data, labels"
      ],
      "metadata": {
        "id": "RjdcuO5kDQXJ"
      },
      "id": "RjdcuO5kDQXJ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f26b608e",
      "metadata": {
        "id": "f26b608e"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Import packages needed to create a image classification model\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import tensorflow as tf\n",
        "\n",
        "from keras.applications.resnet import preprocess_input\n",
        "from keras.layers import Dense,GlobalAveragePooling2D\n",
        "from keras.models import Model\n",
        "\n",
        "from keras.layers import Dense,GlobalAveragePooling2D\n",
        "from keras.callbacks import EarlyStopping\n",
        "from tensorflow import keras\n",
        "\n",
        "IMG_SIZE = (224, 224)\n",
        "\n",
        "\n",
        "# Download the model, valid alpha values [0.25,0.35,0.5,0.75,1]\n",
        "base_model = tf.keras.applications.MobileNetV2(input_shape=(224, 224, 3), include_top=False, weights='imagenet')\n",
        "# Add average pooling to the base\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "model_frozen = Model(inputs=base_model.input,outputs=x)\n",
        "\n",
        "# Get the transformed features from the dataset\n",
        "# TODO: This can be moved to the FE stage of the pipeline\n",
        "# label_map is not used anywhere right now. it has information\n",
        "# about which label is mapped to which number\n",
        "data, labels = convert_tf_dataset(PATH, model_frozen)\n",
        "# Shuffle the dataset for training\n",
        "shuffler = np.random.permutation(len(data))\n",
        "data_shuffled = data[shuffler]\n",
        "labels_shuffled = labels[shuffler]\n",
        "print(data_shuffled)\n",
        "num_features = data_shuffled.shape[1]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_features"
      ],
      "metadata": {
        "id": "VAVqJoag_rXK",
        "collapsed": true
      },
      "id": "VAVqJoag_rXK",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "feature_names = []\n",
        "for a in range(0,num_features):\n",
        "  feature_names.append('feature_' + str(a))\n",
        "feature_names.append('label')\n",
        "df = pd.DataFrame(data=np.hstack((data_shuffled,labels_shuffled)), columns=feature_names)\n",
        "df.head()"
      ],
      "metadata": {
        "id": "Krh6U8TVsIDl"
      },
      "id": "Krh6U8TVsIDl",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the csv\n",
        "df.to_csv('', index=False)"
      ],
      "metadata": {
        "id": "VUyY-iFGs_RT"
      },
      "id": "VUyY-iFGs_RT",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4",
      "include_colab_link": true
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}